import os
import fitz
import streamlit as st
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import faiss
import numpy as np
import tempfile
import google.generativeai as genai
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
genai.configure(api_key=os.getenv("AIzaSyCtN5qIj5G8R1bVS9dFRZvixj5Fy8h33XE"))
model = genai.GenerativeModel("gemini-1.5-flash")

embedder = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

def extract_text_by_page(pdf_path):
    doc = fitz.open(pdf_path)
    return [page.get_text() for page in doc]

def create_faiss_index(texts):
    embeddings = embedder.encode(texts)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(np.array(embeddings).astype('float32'))
    return index, embeddings

def summarize(text):
    korean_prompt = f"ë‹¤ìŒ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”:\n\n{text[:4000]}"
    english_prompt = f"Please summarize the following in English:\n\n{text[:4000]}"
    kr = model.generate_content(korean_prompt).text.strip()
    en = model.generate_content(english_prompt).text.strip()
    return kr, en

def answer_question(text, question):
    prompt = f"""ë‹¤ìŒì€ ì±…ì˜ ì¼ë¶€ì…ë‹ˆë‹¤:

{text[:4000]}

ì§ˆë¬¸: {question}
ë‹µë³€:"""
    return model.generate_content(prompt).text.strip()

def answer_question_with_vector(query, texts, embeddings):
    query_embedding = embedder.encode([query])
    similarities = cosine_similarity(query_embedding, embeddings)[0]
    top_indices = similarities.argsort()[-3:][::-1]
    top_texts = [texts[i] for i in top_indices]
    context = "\n\n".join(top_texts)
    return answer_question(context, query)

# Streamlit UI
st.set_page_config(page_title="ğŸ“„ PDF ë²”ìœ„ ìš”ì•½ ë° ì§ˆì˜ì‘ë‹µ", layout="wide")
st.title("ğŸ“„ PDF êµ¬ê°„ ìš”ì•½ ë° ì§ˆë¬¸ ì±—ë´‡")

uploaded_file = st.file_uploader("ğŸ“¤ PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])

if uploaded_file:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.read())
        pdf_path = tmp_file.name

    all_pages = extract_text_by_page(pdf_path)
    total_pages = len(all_pages)
    st.success(f"ì´ {total_pages} í˜ì´ì§€ë¥¼ ê°€ì§„ PDFê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

    start_page = st.number_input("ì‹œì‘ í˜ì´ì§€ (1ë¶€í„° ì‹œì‘)", min_value=1, max_value=total_pages, value=1)
    end_page = st.number_input("ë í˜ì´ì§€", min_value=1, max_value=total_pages, value=min(5, total_pages))

    if start_page <= end_page:
        selected_texts = all_pages[start_page - 1:end_page]
        section_text = "\n".join(selected_texts)

        st.subheader("4. êµ¬ê°„ ìš”ì•½")
        if st.button("ğŸ“˜ ìš”ì•½ ì‹œì‘"):
            with st.spinner("ìš”ì•½ ì¤‘..."):
                kr_sum, en_sum = summarize(section_text)
                st.markdown("### ğŸ‡°ğŸ‡· í•œêµ­ì–´ ìš”ì•½")
                st.write(kr_sum)
                st.markdown("### ğŸ‡ºğŸ‡¸ ì˜ì–´ ìš”ì•½")
                st.write(en_sum)

        st.subheader("5. êµ¬ê°„ ë‚´ìš©ì—ì„œ ì§ˆë¬¸")
        question1 = st.text_input("ì§ˆë¬¸1 ì…ë ¥:")
        if question1:
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                answer1 = answer_question(section_text, question1)
                st.markdown("### ğŸ¤– ë‹µë³€ 1")
                st.write(answer1)

        st.subheader("6. ì „ì²´ ë‚´ìš©ì—ì„œ ì§ˆë¬¸")
        question2 = st.text_input("ì§ˆë¬¸2 ì…ë ¥:")
        if question2:
            with st.spinner("ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì¤‘..."):
                index, embeddings = create_faiss_index(all_pages)
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    answer2 = answer_question_with_vector(question2, all_pages, embeddings)
                    st.markdown("### ğŸ¤– ë‹µë³€ 2")
                    st.write(answer2)
    else:
        st.warning("ì‹œì‘ í˜ì´ì§€ëŠ” ë í˜ì´ì§€ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.")
