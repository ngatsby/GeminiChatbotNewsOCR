import streamlit as st
import tempfile
import os
from PyPDF2 import PdfReader
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import google.generativeai as genai

# --- Configuration ---
# Ensure the API key is securely accessed
GEMINI_API_KEY = st.secrets.get("AIzaSyCtN5qIj5G8R1bVS9dFRZvixj5Fy8h33XE")
if not GEMINI_API_KEY:
    st.error("Gemini API key not found in Streamlit secrets. Please add 'Key' to your secrets.")
    st.stop() # Stop the app if the key is not found

genai.configure(api_key=GEMINI_API_KEY)

# --- Global Models (Load once for efficiency) ---
@st.cache_resource # Cache the model to avoid re-loading on every rerun
def load_gemini_model():
    return genai.GenerativeModel("models/gemini-pro")

@st.cache_resource # Cache the embedding model
def load_embedding_model():
    return SentenceTransformer("all-MiniLM-L6-v2")

model = load_gemini_model()
embedder = load_embedding_model()

# --- Helper Functions ---
def extract_pages_from_pdf(pdf_file_path):
    try:
        reader = PdfReader(pdf_file_path)
        return [page.extract_text() or "" for page in reader.pages]
    except Exception as e:
        st.error(f"Error extracting text from PDF: {e}")
        return []

def create_embeddings(texts):
    if not texts:
        return np.array([])
    return embedder.encode(texts)

def build_faiss_index(embeddings):
    if embeddings.size == 0:
        return None
    dim = embeddings.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings)
    return index

def ask_gemini(question, context):
    prompt = f"""
    ë‹¤ìŒ ê¸°ì‚¬ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.
    ---
    {context}
    ---
    ì§ˆë¬¸: {question}
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        st.error(f"Error generating response from Gemini: {e}")
        return "I'm sorry, I couldn't generate a response."

# --- Streamlit UI ---
st.title("ğŸ“„ ì¡ì§€/ì±… PDF ì±—ë´‡")

# Initialize session state variables
if "pdf_processed" not in st.session_state:
    st.session_state.pdf_processed = False
if "all_pages" not in st.session_state:
    st.session_state.all_pages = []
if "index" not in st.session_state:
    st.session_state.index = None
if "selected_texts" not in st.session_state:
    st.session_state.selected_texts = []

uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")

if uploaded_file:
    # Use st.session_state to store the uploaded file content if needed across reruns
    # For now, we'll process it once and store derived data.
    if not st.session_state.pdf_processed or st.session_state.uploaded_file_name != uploaded_file.name:
        st.session_state.uploaded_file_name = uploaded_file.name
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_path = tmp_file.name

        with st.spinner("PDFë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
            st.session_state.all_pages = extract_pages_from_pdf(tmp_path)
            st.session_state.pdf_processed = True
            st.success("PDF ì—…ë¡œë“œ ë° í˜ì´ì§€ ì¶”ì¶œ ì™„ë£Œ")

        # Clean up the temporary file immediately after processing
        try:
            os.remove(tmp_path)
        except OSError as e:
            st.warning(f"Warning: Could not remove temporary file {tmp_path}: {e}")

if st.session_state.pdf_processed and st.session_state.all_pages:
    total_pages = len(st.session_state.all_pages)
    st.write(f"ì´ {total_pages} í˜ì´ì§€ê°€ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")

    start_page = st.number_input("ì‹œì‘ í˜ì´ì§€ (1ë¶€í„° ì‹œì‘)", min_value=1, max_value=total_pages, value=1, key="start_page_input")
    end_page = st.number_input("ë í˜ì´ì§€", min_value=start_page, max_value=total_pages, value=min(start_page + 4, total_pages), key="end_page_input") # Suggest a small range

    if st.button("ì„ íƒí•œ êµ¬ê°„ ë¶„ì„ ì‹œì‘", key="analyze_button"):
        with st.spinner("ì„ íƒí•œ êµ¬ê°„ì„ ë²¡í„°í™” ì¤‘ì…ë‹ˆë‹¤..."):
            st.session_state.selected_texts = st.session_state.all_pages[start_page - 1:end_page]
            if st.session_state.selected_texts:
                embeddings = create_embeddings(st.session_state.selected_texts)
                st.session_state.index = build_faiss_index(np.array(embeddings))
                if st.session_state.index:
                    st.success("í•´ë‹¹ êµ¬ê°„ ë²¡í„°í™” ì™„ë£Œ! ì´ì œ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ì„ íƒëœ í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ê±°ë‚˜ ì„ë² ë”©ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("ì„ íƒëœ í˜ì´ì§€ ë²”ìœ„ì— í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    if st.session_state.index:
        question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="question_input")

        if question:
            with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
                try:
                    # Find the most similar sentences
                    question_embedding = embedder.encode([question])
                    D, I = st.session_state.index.search(np.array(question_embedding), k=3)

                    # Ensure indices are within bounds of selected_texts
                    matched_texts = [st.session_state.selected_texts[i] for i in I[0] if i < len(st.session_state.selected_texts)]
                    
                    if matched_texts:
                        context = "\n".join(matched_texts)
                        answer = ask_gemini(question, context)
                        st.markdown("#### ğŸ§  Geminiì˜ ë‹µë³€")
                        st.write(answer)
                    else:
                        st.info("ê´€ë ¨ëœ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                except Exception as e:
                    st.error(f"ì§ˆì˜ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
